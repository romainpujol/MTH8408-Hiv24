{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Romain Pujol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matricule 2343161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 3\n",
    "### Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va coder la méthode limited-BFGS qui prend racine dans la méthode BFGS mais qui nécessite moins d'allocation et de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\") #Accède au fichier Project.toml\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADNLPModel - Model with automatic differentiation backend ADModelBackend{\n",
       "  ForwardDiffADGradient,\n",
       "  ForwardDiffADHvprod,\n",
       "  EmptyADbackend,\n",
       "  EmptyADbackend,\n",
       "  EmptyADbackend,\n",
       "  ForwardDiffADHessian,\n",
       "  EmptyADbackend,\n",
       "}\n",
       "  Problem name: Generic\n",
       "   All variables: ████████████████████ 2      All constraints: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "            free: ████████████████████ 2                 free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "            nnzh: (  0.00% sparsity)   3               linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "                                                    nonlinear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "                                                         nnzj: (------% sparsity)         \n",
       "\n",
       "  Counters:\n",
       "             obj: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 grad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 cons: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "        cons_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             cons_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              jac_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "         jac_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            jprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "       jprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0           jtprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "      jtprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                hprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra, NLPModels, Printf\n",
    "using JSOSolvers, BenchmarkTools, ADNLPModels\n",
    "\n",
    "fH(x) = (x[2]+x[1].^2-11).^2+(x[1]+x[2].^2-7).^2\n",
    "x0H = [10., 20.]\n",
    "himmelblau = ADNLPModel(fH, x0H)\n",
    "\n",
    "problem2 = ADNLPModel(x->-x[1]^2, ones(3))\n",
    "\n",
    "roz(x) = 100 *  (x[2] - x[1]^2)^2 + (x[1] - 1.0)^2\n",
    "rosenbrock = ADNLPModel(roz, [-1.2, 1.0])\n",
    "\n",
    "f(x) = x[1]^2 * (2*x[1] - 3) - 6*x[1]*x[2] * (x[1] - x[2] - 1)\n",
    "pb_du_cours = ADNLPModel(f, [-1.001, -1.001]) #ou [1.5, .5] ou [.5, .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SolverCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearOperators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "armijo (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function armijo(xk, dk, fk, gk, slope, nlp :: AbstractNLPModel; τ1 = 1.0e-4, t_update = 1.5)\n",
    "    t = 1.0\n",
    "    fk_new = obj(nlp, xk + dk) # t = 1.0\n",
    "    while fk_new > fk + τ1 * t * slope\n",
    "      t /= t_update\n",
    "      fk_new = obj(nlp, xk + t * dk)\n",
    "    end\n",
    "    return t, fk_new\n",
    "  end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "limited_bfgs (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function limited_bfgs(nlp      :: AbstractNLPModel;\n",
    "    x        :: AbstractVector = nlp.meta.x0,\n",
    "    atol     :: Real = √eps(eltype(x)), \n",
    "    rtol     :: Real = √eps(eltype(x)),\n",
    "    max_eval :: Int = -1,\n",
    "    max_time :: Float64 = 30.0,\n",
    "    f_min    :: Float64 = -1.0e16,\n",
    "    verbose  :: Bool = true,\n",
    "    mem      :: Int = 5)\n",
    "    \n",
    "start_time = time()\n",
    "elapsed_time = 0.0\n",
    "\n",
    "T = eltype(x)\n",
    "n = nlp.meta.nvar\n",
    "\n",
    "xt = zeros(T, n)\n",
    "∇ft = zeros(T, n)\n",
    "\n",
    "f = obj(nlp, x)\n",
    "∇f = grad(nlp, x)\n",
    "\n",
    "#################################################\n",
    "H = InverseLBFGSOperator(n,mem)\n",
    "#################################################\n",
    "\n",
    "∇fNorm = norm(∇f) #nrm2(n, ∇f)\n",
    "ϵ = atol + rtol * ∇fNorm\n",
    "iter = 0\n",
    "\n",
    "@info log_header([:iter, :f, :dual, :slope, :bk], [Int, T, T, T, T],\n",
    " hdr_override=Dict(:f=>\"f(x)\", :dual=>\"‖∇f‖\", :slope=>\"∇fᵀd\"))\n",
    "\n",
    "optimal = ∇fNorm ≤ ϵ\n",
    "unbdd = f ≤ f_min\n",
    "tired = neval_obj(nlp) > max_eval ≥ 0 || elapsed_time > max_time\n",
    "stalled = false\n",
    "status = :unknown\n",
    "\n",
    "while !(optimal || tired || stalled || unbdd)\n",
    "\n",
    "#################################################\n",
    "d = H*(-∇f)\n",
    "#################################################\n",
    "slope = dot(d, ∇f)\n",
    "if slope ≥ 0\n",
    "@error \"not a descent direction\" slope\n",
    "status = :not_desc\n",
    "stalled = true\n",
    "continue\n",
    "end\n",
    "\n",
    "# Perform improved Armijo linesearch.\n",
    "t, ft = armijo(x, d, f, ∇f, slope, nlp)\n",
    "\n",
    "@info log_row(Any[iter, f, ∇fNorm, slope, t])\n",
    "\n",
    "# Update L-BFGS approximation.\n",
    "xt = x + t * d\n",
    "∇ft = grad(nlp, xt) # grad!(nlp, xt, ∇ft)\n",
    "#################################################\n",
    "push!(H,xt-x,∇ft-∇f)\n",
    "#################################################\n",
    "\n",
    "# Move on.\n",
    "x = xt\n",
    "f = ft\n",
    "∇f = ∇ft\n",
    "\n",
    "∇fNorm = norm(∇f) #nrm2(n, ∇f)\n",
    "iter = iter + 1\n",
    "\n",
    "optimal = ∇fNorm ≤ ϵ\n",
    "unbdd = f ≤ f_min\n",
    "elapsed_time = time() - start_time\n",
    "tired = neval_obj(nlp) > max_eval ≥ 0 || elapsed_time > max_time\n",
    "end\n",
    "\n",
    "@info log_row(Any[iter, f, ∇fNorm])\n",
    "\n",
    "if optimal\n",
    "status = :first_order\n",
    "elseif tired\n",
    "if neval_obj(nlp) > max_eval ≥ 0\n",
    "status = :max_eval\n",
    "elseif elapsed_time > max_time\n",
    "status = :max_time\n",
    "end\n",
    "elseif unbdd\n",
    "status = :unbounded\n",
    "end\n",
    "\n",
    "return GenericExecutionStats(\n",
    "nlp,\n",
    "status=status,\n",
    "solution=x,\n",
    "objective=f,\n",
    "dual_feas=∇fNorm,\n",
    "iter=iter,\n",
    "elapsed_time=elapsed_time,\n",
    ")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"test set\", Any[], 9, false, false, true, 1.707683086045e9, 1.707683086662e9, false, \"c:\\\\Users\\\\romai\\\\POLYMTL\\\\MTH8408-Hiv24\\\\lab3\\\\lab3.ipynb\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Test\n",
    "# Demander le test secret pour lbfgs\n",
    "@testset begin\n",
    "    #Unit/Validation Tests\n",
    "    using Logging, Test\n",
    "    stats = with_logger(NullLogger()) do \n",
    "        limited_bfgs(himmelblau) \n",
    "    end\n",
    "    @test stats.status == :first_order\n",
    "    @test stats.solution ≈ [3.584428266659278, -1.8481265666485827] atol = 1e-6\n",
    "    @show (stats.status, stats.solution)\n",
    "    stats = with_logger(NullLogger()) do \n",
    "        limited_bfgs(problem2) \n",
    "    end\n",
    "    @test stats.status == :unbounded\n",
    "    @show (stats.status, stats.solution)\n",
    "    stats = with_logger(NullLogger()) do \n",
    "        limited_bfgs(rosenbrock) \n",
    "    end\n",
    "    @test stats.solution ≈ [1., 1.] atol = 1e-6\n",
    "    @show (stats.status, stats.solution)\n",
    "    stats = with_logger(NullLogger()) do \n",
    "        limited_bfgs(pb_du_cours, x = [-1.001, -1.001]) \n",
    "    end\n",
    "    @test stats.status == :unbounded\n",
    "    @show (stats.status, stats.solution)\n",
    "    stats = with_logger(NullLogger()) do \n",
    "        limited_bfgs(pb_du_cours, x = [1.5, .5]) \n",
    "    end\n",
    "    @test stats.status == :first_order\n",
    "    @test stats.solution ≈ [1., 0.] atol = 1e-6\n",
    "    @show (stats.status, stats.solution)\n",
    "    stats = with_logger(NullLogger()) do \n",
    "        limited_bfgs(pb_du_cours, x = [.5, .5]) \n",
    "    end\n",
    "    @test stats.status == :first_order\n",
    "    @test stats.solution ≈ [1., 0.] atol = 1e-6\n",
    "    @show (stats.status, stats.solution)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 3282 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m806.400 μs\u001b[22m\u001b[39m … \u001b[35m  9.159 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 79.27%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m  1.438 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m  1.516 ms\u001b[22m\u001b[39m ± \u001b[32m478.136 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m1.05% ±  3.80%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m█\u001b[39m▆\u001b[39m▃\u001b[39m▂\u001b[39m \u001b[39m▁\u001b[34m▁\u001b[39m\u001b[39m▁\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▃\n",
       "  806 μs\u001b[90m           Histogram: frequency by time\u001b[39m         2.52 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m152.89 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m2202\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@benchmark limited_bfgs(himmelblau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m19.500 μs\u001b[22m\u001b[39m … \u001b[35m 8.475 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 98.77%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m20.700 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m22.666 μs\u001b[22m\u001b[39m ± \u001b[32m84.604 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.69% ±  0.99%\n",
       "\n",
       "  \u001b[39m▁\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[34m▇\u001b[39m\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[32m▃\u001b[39m\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  19.5 μs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        36 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m10.77 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m269\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@benchmark lbfgs(himmelblau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction 'lbfgs' du modèle requiert moins de temps de calcul ($21\\mu$s contre $1.4 ms$) et d'allocation (269 contre 2202) pour résoudre le problème Himmelblau. La fonction 'lbfgs' doit être codée de manière plus efficace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester \"facilement\" plusieurs valeurs de $\\tau_1$ dans la fonction armijo, il suffit de le placer en tant que Keyword Arguments et non pas en tant qu'Optional Argument. L'entête de la fonction armijo deviendrait : function armijo(xk, dk, fk, gk, slope, nlp :: AbstractNLPModel, $\\tau_1$ ; t_update = 1.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant coder la méthode du gradient conjugué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cg_optim (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function cg_optim(H, ∇f)\n",
    "    #setup the tolerance:\n",
    "    n∇f = norm(∇f)\n",
    "#####################################\n",
    "    ϵk = minimum([0.5,sqrt(n∇f)])*n∇f\n",
    "####################################\n",
    "    n = length(∇f)\n",
    "    z = zeros(n)\n",
    "    r = ∇f\n",
    "    d = -r\n",
    "    \n",
    "    j = 0\n",
    "    while norm(r) ≥ ϵk && j < 3 * n\n",
    "###############################################\n",
    "        if dot(d, H * d) ≤ 0\n",
    "            if j==0\n",
    "                return -∇f\n",
    "            else\n",
    "                return z\n",
    "            end\n",
    "        end\n",
    "##############################################\n",
    "        α = dot(r,r)/dot(d, H*d)\n",
    "##############################################        \n",
    "        z += α * d\n",
    "        nrr2 = dot(r, r)\n",
    "        r += α * H * d\n",
    "##############################################\n",
    "        if nrr2<ϵk\n",
    "            return z\n",
    "        end\n",
    "        β  = dot(r,r)/dot(r-α * H * d,r-α * H * d)\n",
    "##############################################\n",
    "        d  = -r + β * d\n",
    "        j += 1\n",
    "    end\n",
    "    return z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "armijo_Newton_cg (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function armijo_Newton_cg(nlp      :: AbstractNLPModel;\n",
    "    x        :: AbstractVector = nlp.meta.x0,\n",
    "    atol     :: Real = √eps(eltype(x)), \n",
    "    rtol     :: Real = √eps(eltype(x)),\n",
    "    max_eval :: Int = -1,\n",
    "    max_time :: Float64 = 30.0,\n",
    "    f_min    :: Float64 = -1.0e16)\n",
    "\n",
    "start_time = time()\n",
    "elapsed_time = 0.0\n",
    "\n",
    "T = eltype(x)\n",
    "n = nlp.meta.nvar\n",
    "\n",
    "f = obj(nlp, x)\n",
    "∇f = grad(nlp, x)\n",
    "#################################################\n",
    "H = hess_op(nlp,x)\n",
    "#################################################\n",
    "\n",
    "∇fNorm = norm(∇f) #nrm2(n, ∇f)\n",
    "ϵ = atol + rtol * ∇fNorm\n",
    "iter = 0\n",
    "\n",
    "@info log_header([:iter, :f, :dual, :slope, :bk], [Int, T, T, T, T],\n",
    "hdr_override=Dict(:f=>\"f(x)\", :dual=>\"‖∇f‖\", :slope=>\"∇fᵀd\"))\n",
    "\n",
    "optimal = ∇fNorm ≤ ϵ\n",
    "unbdd = f ≤ f_min\n",
    "tired = neval_obj(nlp) > max_eval ≥ 0 || elapsed_time > max_time\n",
    "stalled = false\n",
    "status = :unknown\n",
    "\n",
    "while !(optimal || tired || stalled || unbdd)\n",
    "\n",
    "    d = cg_optim(H, ∇f)\n",
    "\n",
    "    slope = dot(d, ∇f)\n",
    "    if slope ≥ 0\n",
    "    @error \"not a descent direction\" slope\n",
    "    status = :not_desc\n",
    "    stalled = true\n",
    "    continue\n",
    "    end\n",
    "\n",
    "    # Perform improved Armijo linesearch.\n",
    "    t, f = armijo(x, d, f, ∇f, slope, nlp)\n",
    "\n",
    "    @info log_row(Any[iter, f, ∇fNorm, slope, t])\n",
    "\n",
    "    # Update L-BFGS approximation.\n",
    "    x += t * d\n",
    "    ∇f = grad(nlp, x)\n",
    "    #################################################\n",
    "    H = hess_op(nlp,x)\n",
    "    #################################################\n",
    "\n",
    "    ∇fNorm = norm(∇f) #nrm2(n, ∇f)\n",
    "    iter = iter + 1\n",
    "\n",
    "    optimal = ∇fNorm ≤ ϵ\n",
    "    unbdd = f ≤ f_min\n",
    "    elapsed_time = time() - start_time\n",
    "    tired = neval_obj(nlp) > max_eval ≥ 0 || elapsed_time > max_time\n",
    "end\n",
    "\n",
    "@info log_row(Any[iter, f, ∇fNorm])\n",
    "\n",
    "if optimal\n",
    "status = :first_order\n",
    "elseif tired\n",
    "if neval_obj(nlp) > max_eval ≥ 0\n",
    "status = :max_eval\n",
    "elseif elapsed_time > max_time\n",
    "status = :max_time\n",
    "end\n",
    "elseif unbdd\n",
    "status = :unbounded\n",
    "end\n",
    "\n",
    "return GenericExecutionStats(nlp, status = status, solution=x, objective=f, dual_feas=∇fNorm,\n",
    "         iter=iter, elapsed_time=elapsed_time)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = with_logger(NullLogger()) do \n",
    "    armijo_Newton_cg(himmelblau) \n",
    "end\n",
    "@test stats.status == :first_order\n",
    "@test stats.dual_feas ≤ 1e-6 + 1e-6 * norm(grad(himmelblau, himmelblau.meta.x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = with_logger(NullLogger()) do \n",
    "    armijo_Newton_cg(problem2) \n",
    "end\n",
    "@test stats.status == :unbounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = with_logger(NullLogger()) do \n",
    "    armijo_Newton_cg(rosenbrock) \n",
    "end\n",
    "@test stats.solution ≈ [1., 1.] atol = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = with_logger(NullLogger()) do \n",
    "    armijo_Newton_cg(pb_du_cours, x = [.5, .5]) \n",
    "end\n",
    "@test stats.status == :first_order\n",
    "@test stats.solution ≈ [1., 0.] atol = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tests sont réussis !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que les implémentations sont faites, on peut passer aux exercices du PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Exercice 1 \n",
    "On va résoudre le problème \"genrose\" que j'ai résolu au dernier laboratoire comme ça je sais vers quoi on doit converger : le vecteur rempli de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using OptimizationProblems\n",
    "using ADNLPModels, OptimizationProblems.ADNLPProblems\n",
    "\n",
    "n = 100\n",
    "model = genrose(n=n)\n",
    "@test unconstrained(model) #on vérifie qu'on est bien dans un modèle sans contrainte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Float64}:\n",
       " 1.0000000001795355\n",
       " 1.0000000002407166\n",
       " 1.0000000003020546\n",
       " 1.0000000003505547\n",
       " 1.0000000004277545\n",
       " 1.000000000414482\n",
       " 1.0000000003459237\n",
       " 1.0000000000797196\n",
       " 0.9999999998438878\n",
       " 0.9999999995206177\n",
       " ⋮\n",
       " 0.9999999998406989\n",
       " 0.9999999997229829\n",
       " 0.9999999994597167\n",
       " 0.9999999989519792\n",
       " 0.9999999978546621\n",
       " 0.9999999956862801\n",
       " 0.9999999912861994\n",
       " 0.9999999825027955\n",
       " 0.9999999648957821"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limited_bfgs(model).solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui est le cas ! On converge bien vers le point attendu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Exercice 2 \n",
    "Même combat que l'exercice précédent, je vais prendre un problème résolu au dernier lab, le problème tridia où la solution est $v=(\\frac{1}{2^{i-1}})_{i\\in[1,n]}$ où $n$ est la taille du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=100\n",
    "model2=tridia(n=n)\n",
    "@test unconstrained(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Float64}:\n",
       "  1.0000074265509098\n",
       "  0.5000042348966984\n",
       "  0.25000230542583446\n",
       "  0.12500122746441464\n",
       "  0.0625006450737\n",
       "  0.031250336119284856\n",
       "  0.01562517408047534\n",
       "  0.00781258975340332\n",
       "  0.0039062961147050875\n",
       "  0.001953148627818381\n",
       "  ⋮\n",
       "  1.071478929090357e-9\n",
       " -1.5501026627733622e-9\n",
       "  2.1098051585679768e-9\n",
       " -2.6797278095709528e-9\n",
       "  3.138352395940997e-9\n",
       " -3.3245337811783996e-9\n",
       "  3.075454847120296e-9\n",
       " -2.2922553730372632e-9\n",
       "  1.0177602433463937e-9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "armijo_Newton_cg(model2).solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est à peu près le cas, les erreurs numériques se voient beaucoup pour la fin de la solution mais ça reste tolérable car on a toujours une certaine tolérance de l'ordre de $10^{-6}$ en général."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `AMPGO02` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `AMPGO02` not defined\n"
     ]
    }
   ],
   "source": [
    "using NLPModels, NLPModelsJuMP, OptimizationProblems, OptimizationProblems.PureJuMP, SolverBenchmark\n",
    "using ADNLPModels\n",
    "\n",
    "n = 50 # taille des problemes, 4 < n < 101 pour satisfaire skip_if\n",
    "\n",
    "solvers=Dict(\n",
    "    :limited_bfgs_1 => model -> limited_bfgs(model, mem=1),\n",
    "    :limited_bfgs_5 => model -> limited_bfgs(model, mem=5),\n",
    "    :limited_bfgs_20 => model -> limited_bfgs(model, mem=20),\n",
    "    )\n",
    "\n",
    "ad_problems = (eval(Meta.parse(problem))(;n) for problem ∈ OptimizationProblems.meta[!, :name])\n",
    "    \n",
    "stats = bmark_solvers(\n",
    "  solvers, ad_problems,\n",
    "  skipif=prob -> (!unconstrained(prob) || get_nvar(prob) > 100 || get_nvar(prob) < 5),\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Exercice 4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
